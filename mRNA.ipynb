{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(2020)\n",
    "np.random.seed(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will tell us the columns we are predicting\n",
    "pred_cols = ['reactivity', 'deg_Mg_pH10', 'deg_Mg_50C', 'deg_pH10', 'deg_50C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.random.normal((32, 68, 3))\n",
    "y_pred = tf.random.normal((32, 68, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCRMSE(y_true, y_pred):\n",
    "    colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n",
    "    return tf.reduce_mean(tf.sqrt(colwise_mse), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru_layer(hidden_dim, dropout):\n",
    "    return L.Bidirectional(L.GRU(\n",
    "        hidden_dim, dropout=dropout, return_sequences=True, kernel_initializer='orthogonal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(embed_size, seq_len=107, pred_len=68, dropout=0.5, \n",
    "                sp_dropout=0.2, embed_dim=200, hidden_dim=256, n_layers=3):\n",
    "    inputs = L.Input(shape=(seq_len, 3))\n",
    "    embed = L.Embedding(input_dim=embed_size, output_dim=embed_dim)(inputs)\n",
    "    \n",
    "    reshaped = tf.reshape(\n",
    "        embed, shape=(-1, embed.shape[1],  embed.shape[2] * embed.shape[3])\n",
    "    )\n",
    "    hidden = L.SpatialDropout1D(sp_dropout)(reshaped)\n",
    "    \n",
    "    for x in range(n_layers):\n",
    "        hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
    "    \n",
    "    # Since we are only making predictions on the first part of each sequence, \n",
    "    # we have to truncate it\n",
    "    truncated = hidden[:, :pred_len]\n",
    "    out = L.Dense(5, activation='linear')(truncated)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=out)\n",
    "    model.compile(tf.optimizers.Adam(), loss=MCRMSE)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_list_to_array(df):\n",
    "    \"\"\"\n",
    "    Input: dataframe of shape (x, y), containing list of length l\n",
    "    Return: np.array of shape (x, l, y)\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.transpose(\n",
    "        np.array(df.values.tolist()),\n",
    "        (0, 2, 1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_inputs(df, token2int, cols=['sequence', 'structure', 'predicted_loop_type']):\n",
    "    return pandas_list_to_array(\n",
    "        df[cols].applymap(lambda seq: [token2int[x] for x in seq])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json(os.path.join('E:\\Datasets\\MRNA','train.json') , lines = True)\n",
    "test = pd.read_json(os.path.join('E:\\Datasets\\MRNA','test.json') , lines = True)\n",
    "sample_sub = pd.read_csv(os.path.join('E:\\Datasets\\MRNA','sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.query(\"signal_to_noise >= 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use this dictionary to map each character to an integer\n",
    "# so that it can be used as an input in keras\n",
    "token2int = {x:i for i, x in enumerate('().ACGUBEHIMSX')}\n",
    "\n",
    "train_inputs = preprocess_inputs(train, token2int)\n",
    "train_labels = pandas_list_to_array(train[pred_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    train_inputs, train_labels, test_size=.1, random_state=34, stratify=train.SN_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_df = test.query(\"seq_length == 107\")\n",
    "private_df = test.query(\"seq_length == 130\")\n",
    "\n",
    "public_inputs = preprocess_inputs(public_df, token2int)\n",
    "private_inputs = preprocess_inputs(private_df, token2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 107, 3)]          0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 107, 3, 200)       2800      \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorF [(None, 107, 600)]        0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 107, 600)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 107, 512)          1317888   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 107, 512)          1182720   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 107, 512)          1182720   \n",
      "_________________________________________________________________\n",
      "tf_op_layer_strided_slice (T [(None, 68, 512)]         0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 68, 5)             2565      \n",
      "=================================================================\n",
      "Total params: 3,688,693\n",
      "Trainable params: 3,688,693\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(embed_size=len(token2int))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1887 samples, validate on 210 samples\n",
      "Epoch 1/75\n",
      "1887/1887 - 73s - loss: 0.4536 - val_loss: 0.3811\n",
      "Epoch 2/75\n",
      "1887/1887 - 31s - loss: 0.3852 - val_loss: 0.3557\n",
      "Epoch 3/75\n",
      "1887/1887 - 31s - loss: 0.3623 - val_loss: 0.3424\n",
      "Epoch 4/75\n",
      "1887/1887 - 31s - loss: 0.3494 - val_loss: 0.3271\n",
      "Epoch 5/75\n",
      "1887/1887 - 35s - loss: 0.3396 - val_loss: 0.3208\n",
      "Epoch 6/75\n",
      "1887/1887 - 42s - loss: 0.3323 - val_loss: 0.3163\n",
      "Epoch 7/75\n",
      "1887/1887 - 47s - loss: 0.3250 - val_loss: 0.3140\n",
      "Epoch 8/75\n",
      "1887/1887 - 42s - loss: 0.3165 - val_loss: 0.2995\n",
      "Epoch 9/75\n",
      "1887/1887 - 35s - loss: 0.3087 - val_loss: 0.2993\n",
      "Epoch 10/75\n",
      "1887/1887 - 36s - loss: 0.3039 - val_loss: 0.2999\n",
      "Epoch 11/75\n",
      "1887/1887 - 35s - loss: 0.2970 - val_loss: 0.2809\n",
      "Epoch 12/75\n",
      "1887/1887 - 44s - loss: 0.2904 - val_loss: 0.2811\n",
      "Epoch 13/75\n",
      "1887/1887 - 39s - loss: 0.2837 - val_loss: 0.2712\n",
      "Epoch 14/75\n",
      "1887/1887 - 40s - loss: 0.2769 - val_loss: 0.2663\n",
      "Epoch 15/75\n",
      "1887/1887 - 40s - loss: 0.2697 - val_loss: 0.2577\n",
      "Epoch 16/75\n",
      "1887/1887 - 46s - loss: 0.2638 - val_loss: 0.2542\n",
      "Epoch 17/75\n",
      "1887/1887 - 43s - loss: 0.2585 - val_loss: 0.2514\n",
      "Epoch 18/75\n",
      "1887/1887 - 38s - loss: 0.2548 - val_loss: 0.2537\n",
      "Epoch 19/75\n",
      "1887/1887 - 36s - loss: 0.2514 - val_loss: 0.2475\n",
      "Epoch 20/75\n",
      "1887/1887 - 38s - loss: 0.2478 - val_loss: 0.2487\n",
      "Epoch 21/75\n",
      "1887/1887 - 36s - loss: 0.2456 - val_loss: 0.2419\n",
      "Epoch 22/75\n",
      "1887/1887 - 41s - loss: 0.2412 - val_loss: 0.2392\n",
      "Epoch 23/75\n",
      "1887/1887 - 35s - loss: 0.2386 - val_loss: 0.2389\n",
      "Epoch 24/75\n",
      "1887/1887 - 40s - loss: 0.2355 - val_loss: 0.2366\n",
      "Epoch 25/75\n",
      "1887/1887 - 36s - loss: 0.2345 - val_loss: 0.2361\n",
      "Epoch 26/75\n",
      "1887/1887 - 35s - loss: 0.2324 - val_loss: 0.2359\n",
      "Epoch 27/75\n",
      "1887/1887 - 36s - loss: 0.2303 - val_loss: 0.2372\n",
      "Epoch 28/75\n",
      "1887/1887 - 36s - loss: 0.2281 - val_loss: 0.2354\n",
      "Epoch 29/75\n",
      "1887/1887 - 37s - loss: 0.2273 - val_loss: 0.2344\n",
      "Epoch 30/75\n",
      "1887/1887 - 36s - loss: 0.2251 - val_loss: 0.2321\n",
      "Epoch 31/75\n",
      "1887/1887 - 51s - loss: 0.2216 - val_loss: 0.2318\n",
      "Epoch 32/75\n",
      "1887/1887 - 58s - loss: 0.2192 - val_loss: 0.2311\n",
      "Epoch 33/75\n",
      "1887/1887 - 63s - loss: 0.2191 - val_loss: 0.2278\n",
      "Epoch 34/75\n",
      "1887/1887 - 55s - loss: 0.2165 - val_loss: 0.2283\n",
      "Epoch 35/75\n",
      "1887/1887 - 47s - loss: 0.2147 - val_loss: 0.2321\n",
      "Epoch 36/75\n",
      "1887/1887 - 42s - loss: 0.2142 - val_loss: 0.2293\n",
      "Epoch 37/75\n",
      "1887/1887 - 43s - loss: 0.2122 - val_loss: 0.2271\n",
      "Epoch 38/75\n",
      "1887/1887 - 37s - loss: 0.2092 - val_loss: 0.2270\n",
      "Epoch 39/75\n",
      "1887/1887 - 36s - loss: 0.2089 - val_loss: 0.2250\n",
      "Epoch 40/75\n",
      "1887/1887 - 36s - loss: 0.2060 - val_loss: 0.2276\n",
      "Epoch 41/75\n",
      "1887/1887 - 35s - loss: 0.2052 - val_loss: 0.2261\n",
      "Epoch 42/75\n",
      "1887/1887 - 36s - loss: 0.2035 - val_loss: 0.2295\n",
      "Epoch 43/75\n",
      "1887/1887 - 35s - loss: 0.2025 - val_loss: 0.2233\n",
      "Epoch 44/75\n",
      "1887/1887 - 36s - loss: 0.2011 - val_loss: 0.2244\n",
      "Epoch 45/75\n",
      "1887/1887 - 38s - loss: 0.1999 - val_loss: 0.2241\n",
      "Epoch 46/75\n",
      "1887/1887 - 36s - loss: 0.1994 - val_loss: 0.2243\n",
      "Epoch 47/75\n",
      "1887/1887 - 35s - loss: 0.1977 - val_loss: 0.2221\n",
      "Epoch 48/75\n",
      "1887/1887 - 35s - loss: 0.1957 - val_loss: 0.2224\n",
      "Epoch 49/75\n",
      "1887/1887 - 38s - loss: 0.1954 - val_loss: 0.2238\n",
      "Epoch 50/75\n",
      "1887/1887 - 35s - loss: 0.1942 - val_loss: 0.2220\n",
      "Epoch 51/75\n",
      "1887/1887 - 34s - loss: 0.1925 - val_loss: 0.2222\n",
      "Epoch 52/75\n",
      "1887/1887 - 35s - loss: 0.1920 - val_loss: 0.2224\n",
      "Epoch 53/75\n",
      "1887/1887 - 34s - loss: 0.1898 - val_loss: 0.2219\n",
      "Epoch 54/75\n",
      "1887/1887 - 33s - loss: 0.1892 - val_loss: 0.2232\n",
      "Epoch 55/75\n",
      "1887/1887 - 33s - loss: 0.1882 - val_loss: 0.2222\n",
      "Epoch 56/75\n",
      "1887/1887 - 33s - loss: 0.1843 - val_loss: 0.2200\n",
      "Epoch 57/75\n",
      "1887/1887 - 33s - loss: 0.1824 - val_loss: 0.2190\n",
      "Epoch 58/75\n",
      "1887/1887 - 33s - loss: 0.1816 - val_loss: 0.2187\n",
      "Epoch 59/75\n",
      "1887/1887 - 33s - loss: 0.1811 - val_loss: 0.2185\n",
      "Epoch 60/75\n",
      "1887/1887 - 35s - loss: 0.1810 - val_loss: 0.2188\n",
      "Epoch 61/75\n",
      "1887/1887 - 41s - loss: 0.1808 - val_loss: 0.2186\n",
      "Epoch 62/75\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    batch_size=64,\n",
    "    epochs=75,\n",
    "    verbose=2,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(patience=5),\n",
    "        tf.keras.callbacks.ModelCheckpoint('model.h5')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(\n",
    "    history.history, y=['loss', 'val_loss'],\n",
    "    labels={'index': 'epoch', 'value': 'MCRMSE'}, \n",
    "    title='Training History')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caveat: The prediction format requires the output to be the same length as the input,\n",
    "# although it's not the case for the training data.\n",
    "model_public = build_model(seq_len=107, pred_len=107, embed_size=len(token2int))\n",
    "model_private = build_model(seq_len=130, pred_len=130, embed_size=len(token2int))\n",
    "\n",
    "model_public.load_weights('model.h5')\n",
    "model_private.load_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_preds = model_public.predict(public_inputs)\n",
    "private_preds = model_private.predict(private_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_ls = []\n",
    "\n",
    "for df, preds in [(public_df, public_preds), (private_df, private_preds)]:\n",
    "    for i, uid in enumerate(df.id):\n",
    "        single_pred = preds[i]\n",
    "\n",
    "        single_df = pd.DataFrame(single_pred, columns=pred_cols)\n",
    "        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n",
    "\n",
    "        preds_ls.append(single_df)\n",
    "\n",
    "preds_df = pd.concat(preds_ls)\n",
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = sample_df[['id_seqpos']].merge(preds_df, on=['id_seqpos'])\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
